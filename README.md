# n8n AI Assistant Backend

Backend API pour l'extension Chrome n8n AI Assistant. Ce backend fait le pont entre l'extension Chrome et l'API Claude d'Anthropic pour permettre la cr√©ation et modification de workflows n8n en langage naturel.

## üöÄ Fonctionnalit√©s

- **G√©n√©ration de workflows n8n** : Cr√©ation de workflows complets √† partir de descriptions en langage naturel
- **Modification intelligente** : Modification de workflows existants avec des commandes naturelles
- **Node-Types dynamiques** : Synchronisation hebdomadaire avec n8n:latest pour toujours avoir les derniers nodes
- **Compatibilit√© garantie** : Utilise les versions exactes des nodes de votre instance n8n
- **Streaming en temps r√©el** : R√©ponses en streaming via Server-Sent Events
- **S√©curis√©** : Authentification par token Bearer

## üìã Pr√©requis

- Node.js 18+ install√©
- Un compte Anthropic avec acc√®s √† l'API Claude
- (Optionnel mais recommand√©) Un compte OpenAI pour les embeddings
- (Optionnel mais recommand√©) Un compte Pinecone pour le stockage vectoriel
- Un compte Railway pour le d√©ploiement

## üõ†Ô∏è Installation

### 1. Cloner le repository
```bash
git clone <your-repo-url>
cd cursor-n8n-backend
```

### 2. Installer les d√©pendances
```bash
npm install
```

### 3. Configurer les variables d'environnement
```bash
cp env.example .env
```

√âditer `.env` et ajouter vos cl√©s :

#### Configuration minimale (sans RAG)
```env
# OBLIGATOIRE
CLAUDE_API_KEY=sk-ant-api03-...  # Obtenir sur https://console.anthropic.com/
BACKEND_API_KEY=your-secure-token  # G√©n√©rer avec: openssl rand -hex 32
```

#### Configuration compl√®te (avec RAG Pinecone)
```env
# OBLIGATOIRE
CLAUDE_API_KEY=sk-ant-api03-...
BACKEND_API_KEY=your-secure-token

# RAG (recommand√© pour de meilleures r√©ponses)
OPENAI_API_KEY=sk-...  # Pour g√©n√©rer les embeddings
PINECONE_API_KEY=...   # Stockage vectoriel (gratuit jusqu'√† 100k vecteurs)
```

### 4. Lancer en d√©veloppement
```bash
npm run dev
```

L'API sera disponible sur `http://localhost:3000/api/claude`

## üîç Configuration du syst√®me Node-Types

Le syst√®me Node-Types synchronise automatiquement les m√©tadonn√©es des nodes n8n pour garantir la compatibilit√©.

### √âtapes de configuration :

1. **Cr√©er un compte Pinecone gratuit**
   - Aller sur [pinecone.io](https://www.pinecone.io/)
   - Le plan gratuit permet 100k vecteurs (largement suffisant)

2. **Obtenir une cl√© OpenAI**
   - N√©cessaire pour g√©n√©rer les embeddings des nodes
   - Co√ªt minimal (~$0.01 pour indexer tous les nodes)

3. **Premi√®re indexation**
   ```bash
   # Si vous avez n8n en local
   npm run update-nodes
   
   # Sinon, avec Docker
   npm run update-nodes:docker
   ```

4. **Mise √† jour automatique**
   - Railway ex√©cute automatiquement `npm run cron:weekly` tous les lundis
   - Les nodes sont toujours synchronis√©s avec n8n:latest

### Fonctionnement :

1. **R√©cup√©ration** : Appel √† `/rest/node-types` de n8n pour obtenir tous les nodes
2. **Indexation** : Chaque node est stock√© avec son ID unique `nodeName|vX`
3. **Identification** : Claude Haiku identifie les nodes mentionn√©s dans le prompt
4. **Enrichissement** : Les m√©tadonn√©es exactes sont ajout√©es au contexte
5. **G√©n√©ration** : Claude Opus cr√©e le workflow avec les bonnes versions

## üì¶ D√©ploiement sur Railway

Railway est recommand√© car il n'a pas de limite de timeout (contrairement √† Vercel).

### D√©ploiement rapide :

1. **Pusher sur GitHub**
```bash
git add .
git commit -m "Initial commit"
git push origin main
```

2. **D√©ployer sur Railway**
- Aller sur [railway.app](https://railway.app)
- "New Project" ‚Üí "Deploy from GitHub repo"
- S√©lectionner votre repository

3. **Configurer les variables**
Dans Railway, ajouter toutes les variables de votre `.env`

4. **URL publique**
Railway g√©n√®re automatiquement une URL comme `https://your-app.railway.app`

## üì° Utilisation de l'API

### Endpoint principal
```
POST https://your-app.railway.app/api/claude
```

### Headers requis
```javascript
{
  'Authorization': 'Bearer YOUR_BACKEND_API_KEY',
  'Content-Type': 'application/json'
}
```

### Body de la requ√™te
```json
{
  "prompt": "Cr√©e un workflow qui envoie un email tous les matins",
  "context": {
    "nodes": [],
    "connections": {}
  },
  "tools": [],
  "mode": "create",
  "versions": {
    "gmail": 2,
    "schedule": 1,
    "httpRequest": 5
    // ... mapping complet des versions
  }
}
```

### Exemple avec cURL
```bash
curl -X POST https://your-app.railway.app/api/claude \
  -H "Authorization: Bearer YOUR_BACKEND_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Cr√©e un workflow simple avec un webhook trigger",
    "context": {},
    "tools": [],
    "mode": "create"
  }'
```

## üîß Configuration de l'extension Chrome

Mettre √† jour `src/config.js` dans l'extension :

```javascript
const CONFIG = {
  API_URL: 'https://your-app.railway.app/api/claude',
  API_KEY: 'your-backend-api-key',
};
```

## üìä Monitoring et Debug

### V√©rifier le statut
```bash
curl https://your-app.railway.app/api
```

R√©ponse attendue :
```json
{
  "status": "ok",
  "environment": {
    "claude_configured": true,
    "backend_auth_configured": true,
    "openai_configured": true,
    "pinecone_configured": true,
    "rag_available": true
  }
}
```

### Logs Railway
```bash
railway logs --follow
```

## üö® Troubleshooting

### Les node-types ne se chargent pas
1. V√©rifier que `OPENAI_API_KEY` et `PINECONE_API_KEY` sont configur√©es
2. Ex√©cuter `npm run update-nodes` pour indexer manuellement
3. V√©rifier que n8n est accessible sur le port configur√©

### Erreur "Index not found" Pinecone
- L'index sera cr√©√© automatiquement lors de la premi√®re mise √† jour
- Attendre 1-2 minutes que l'index soit pr√™t

### Versions incorrectes
- L'extension doit envoyer le mapping `versions` dans chaque requ√™te
- V√©rifier que l'extension r√©cup√®re bien les node-types au chargement

### Performances lentes
- La premi√®re requ√™te apr√®s d√©ploiement peut √™tre lente (cold start)
- L'indexation initiale prend 2-3 minutes
- Les requ√™tes suivantes sont rapides (~1-2s)

## üéØ Optimisations possibles

1. **Cache local** : Ajouter Redis pour cacher les embeddings fr√©quents
2. **Mod√®le d'embeddings** : Utiliser `text-embedding-3-large` pour plus de pr√©cision
3. **Chunking** : Ajuster `CHUNK_SIZE` selon vos besoins
4. **Filtres** : Utiliser les m√©tadonn√©es Pinecone pour filtrer par type de node

## üìÑ License

MIT License - Voir LICENSE pour plus de d√©tails 