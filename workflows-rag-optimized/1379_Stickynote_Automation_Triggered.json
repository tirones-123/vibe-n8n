{
  "id": "af8RV5b2TWB2LclA",
  "meta": {
    "instanceId": "<UUID-chain>"
  },
  "name": "Chat with local LLMs using n8n and Ollama",
  "tags": [],
  "nodes": [
    {
      "id": "475385fa-28f3-45c4-bd1a-10dde79f74f2",
      "name": "When chat message received",
      "type": "@n8n/n8n-nodes-langchain.chatTrigger",
      "position": [
        700,
        460
      ],
      "webhookId": "ebdeba3f-6b4f-49f3-ba0a-8253dd226161",
      "parameters": {
        "options": {}
      },
      "typeVersion": 1.1
    },
    {
      "id": "61133dc6-dcd9-44ff-85f2-5d8cc2ce813e",
      "name": "Ollama Chat Model",
      "type": "@n8n/n8n-nodes-langchain.lmChatOllama",
      "position": [
        900,
        680
      ],
      "parameters": {
        "options": {}
      },
      "credentials": {
        "ollamaApi": {
          "id": "<ollamaApi-id>",
          "name": "Local Ollama"
        }
      },
      "typeVersion": 1
    },
    {
      "id": "eeffdd4e-6795-4ebc-84f7-87b5ac4167d9",
      "name": "Chat LLM Chain",
      "type": "@n8n/n8n-nodes-langchain.chainLlm",
      "position": [
        920,
        460
      ],
      "parameters": {},
      "typeVersion": 1.4
    }
  ],
  "active": false,
  "settings": {
    "executionOrder": "v1"
  },
  "connections": {
    "Ollama Chat Model": {
      "ai_languageModel": [
        [
          {
            "node": "Chat LLM Chain",
            "type": "ai_languageModel",
            "index": 0
          }
        ]
      ]
    },
    "When chat message received": {
      "main": [
        [
          {
            "node": "Chat LLM Chain",
            "type": "main",
            "index": 0
          }
        ]
      ]
    }
  }
}