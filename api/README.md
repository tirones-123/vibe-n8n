# n8n Workflow RAG Backend API

Backend intelligent pour la g√©n√©ration de workflows n8n bas√© sur RAG (Retrieval-Augmented Generation) avec Claude 4 Sonnet, Pinecone et plus de 2055 exemples de workflows r√©els.

## üöÄ Vue d'ensemble

Ce backend fournit une API REST avec streaming SSE pour g√©n√©rer des workflows n8n complets bas√©s sur des descriptions en langage naturel. Il utilise un syst√®me RAG sophistiqu√© qui :

1. **Recherche s√©mantique** dans 2055+ workflows index√©s dans Pinecone
2. **S√©lectionne les 3 meilleurs exemples** les plus pertinents
3. **G√©n√®re un workflow complet** avec Claude 4 Sonnet
4. **Valide et optimise** la structure pour n8n
5. **Streaming temps r√©el** avec feedback de progression

## üìä Architecture

```mermaid
graph TD
    A[Extension Chrome] --> B[API Claude /api/claude]
    B --> C[Workflow RAG Service]
    C --> D[Pinecone Vector Search]
    C --> E[Claude 4 Sonnet]
    C --> F[OpenAI Embeddings]
    D --> G[2055+ Workflows DB]
    C --> H[SSE Streaming Response]
    H --> A
```

## üìÅ Structure des fichiers

```
api/
‚îú‚îÄ‚îÄ README.md                    # Ce fichier
‚îú‚îÄ‚îÄ index.js                     # Routes principales et health checks
‚îú‚îÄ‚îÄ claude.js                    # Handler principal g√©n√©ration workflows
‚îî‚îÄ‚îÄ rag/
    ‚îî‚îÄ‚îÄ workflow-rag-service.js   # Service RAG complet (Pinecone + Claude)
```

## üõ†Ô∏è Configuration requise

### Variables d'environnement

```bash
# Claude API (requis)
CLAUDE_API_KEY=sk-ant-api03-...

# Pinecone Vector Database (requis)
PINECONE_API_KEY=your-pinecone-key
PINECONE_WORKFLOW_INDEX=n8n-workflows

# OpenAI pour embeddings (requis)
OPENAI_API_KEY=sk-...

# Authentification backend (requis)
BACKEND_API_KEY=your-secure-backend-key

# Optionnel
NODE_ENV=production
```

### D√©pendances

```json
{
  "@pinecone-database/pinecone": "^3.0.0",
  "@anthropic-ai/sdk": "^0.27.0",
  "openai": "^4.63.0"
}
```

## üåê Endpoints API

### `POST /api/claude`

**G√©n√©ration de workflows avec streaming SSE**

#### Headers requis
```
Authorization: Bearer YOUR_BACKEND_API_KEY
Content-Type: application/json
```

#### Payload - Mode G√©n√©ration (nouveau workflow)
```json
{
  "prompt": "Cr√©e un workflow qui synchronise Slack avec Notion toutes les heures"
}
```

#### Payload - Mode Am√©lioration (workflow existant)
```json
{
  "prompt": "Ajoute une notification par email en cas d'erreur",
  "baseWorkflow": {
    "name": "Mon workflow existant",
    "nodes": [...],
    "connections": {...}
  }
}
```

#### R√©ponse Streaming (SSE)

**√âv√©nements de progression :**
```
data: {"type": "setup", "data": {"message": "Initialisation du service RAG..."}}

data: {"type": "search", "data": {"message": "Recherche de workflows similaires..."}}

data: {"type": "context_building", "data": {"message": "Construction du contexte...", "workflows": ["Workflow 1", "Workflow 2"]}}

data: {"type": "claude_call", "data": {"message": "G√©n√©ration avec Claude 4 Sonnet...", "promptLength": 15420}}

data: {"type": "parsing", "data": {"message": "Traitement de la r√©ponse..."}}
```

**Workflow simple (< 10KB) :**
```
data: {"type": "complete", "data": {"success": true, "workflow": {...}, "explanation": {...}}}
```

**Workflow moyen (10-100KB) :**
```
data: {"type": "compression", "data": {"message": "Compression du workflow...", "nodesCount": 15}}

data: {"type": "compressed_complete", "data": {"success": true, "compressed": true, "data": "base64...", "originalSize": 25600}}
```

**Gros workflow (> 100KB) :**
```
data: {"type": "chunking_start", "data": {"message": "Envoi en 5 parties...", "totalChunks": 5}}

data: {"type": "chunk", "data": {"index": 0, "total": 5, "data": "...", "isLast": false}}
...
data: {"type": "chunk", "data": {"index": 4, "total": 5, "data": "...", "isLast": true}}

data: {"type": "chunking_complete", "data": {"message": "Workflow transmis avec succ√®s!", "totalChunks": 5}}
```

### `GET /api`

**Health check et informations**

```json
{
  "status": "ok",
  "environment": "RAG Workflow Backend",
  "timestamp": "2025-01-17T10:30:00.000Z",
  "endpoints": {
    "/api/claude": "POST - G√©n√©ration de workflows (SSE)",
    "/api/fallback": "POST - R√©cup√©ration fallback",
    "/api/status": "GET - Monitoring du syst√®me"
  }
}
```

### `GET /api/status`

**Monitoring du syst√®me**

```json
{
  "status": "operational",
  "timestamp": "2025-01-17T10:30:00.000Z",
  "uptime": 86400.123,
  "memory": {
    "rss": 134217728,
    "heapTotal": 67108864,
    "heapUsed": 45088768,
    "external": 2097152
  },
  "environment": "production"
}
```

### `POST /api/fallback`

**R√©cup√©ration fallback pour gros workflows**

```json
{
  "sessionId": "session_1705491234567_abc123",
  "action": "get_workflow"
}
```

## üéØ Syst√®me RAG D√©taill√©

### 1. Base de connaissances
- **2055+ workflows** r√©els index√©s dans Pinecone
- **Descriptions GPT-4** pour chaque workflow
- **Embeddings text-embedding-3-small** pour recherche s√©mantique
- **M√©tadonn√©es** : types de n≈ìuds, complexit√©, domaine d'application

### 2. Pipeline de g√©n√©ration

#### √âtape 1 : Recherche s√©mantique
```javascript
// G√©n√©ration embedding de la requ√™te utilisateur
const embedding = await openai.embeddings.create({
  model: 'text-embedding-3-small',
  input: userDescription
});

// Recherche dans Pinecone (top 3)
const results = await pinecone.query({
  vector: embedding,
  topK: 3,
  includeMetadata: true
});
```

#### √âtape 2 : Construction du contexte
```javascript
// Chargement des workflows complets depuis workflows-rag-optimized/
const workflows = await Promise.all(
  results.matches.map(match => 
    fs.readFile(`workflows-rag-optimized/${match.metadata.filename}`)
  )
);
```

#### √âtape 3 : G√©n√©ration Claude
```javascript
const response = await anthropic.messages.create({
  model: 'claude-sonnet-4-20250514',
  max_tokens: 18000,
  temperature: 0.3,
  system: systemPrompt,
  messages: [{ role: 'user', content: userPrompt }]
});
```

### 3. Optimisations de transmission

**Petits workflows (< 10KB)**
- Envoi direct JSON

**Workflows moyens (10KB - 100KB)**
- Compression gzip + base64
- D√©compression c√¥t√© client

**Gros workflows (> 100KB)**
- D√©coupage en chunks de 32KB
- Transmission s√©quentielle avec d√©lais
- R√©assemblage c√¥t√© client

## üìä Monitoring et Statistiques

Le backend maintient des statistiques en temps r√©el :

```javascript
let requestStats = {
  total: 0,           // Nombre total de requ√™tes
  success: 0,         // Requ√™tes r√©ussies
  errors: 0,          // Requ√™tes √©chou√©es
  largeWorkflows: 0,  // Workflows > 50KB
  compressionUsed: 0, // Fois o√π compression utilis√©e
  chunkingUsed: 0     // Fois o√π chunking utilis√©
};
```

### Logs d√©taill√©s

Chaque requ√™te produit des logs complets :

```
üöÄ === WORKFLOW RAG REQUEST 42 ===
üìä Stats actuelles: {total: 42, success: 38, errors: 4}
üìù Prompt: "Cr√©e un workflow qui..."
üîÑ Mode d√©tect√©: GENERATION
üîç Pinecone: 3 workflows trouv√©s
ü§ñ Claude: 15420 chars de prompt
üì¶ Workflow: 45KB (compression activ√©e)
‚úÖ Succ√®s en 8.5s
```

## üöÄ D√©ploiement

### Railway (Production)

1. **Connecter le repo** √† Railway
2. **Configurer les variables** d'environnement
3. **D√©ployer** automatiquement

```bash
# URL de production
https://vibe-n8n-production.up.railway.app
```

### Vercel (Backup)

```bash
# D√©ploiement
vercel --prod

# URL de backup
https://vibe-n8n.vercel.app
```

### Local (D√©veloppement)

```bash
# Installation
npm install

# Configuration
cp .env.example .env
# √âditer .env avec vos cl√©s API

# D√©marrage
npm start

# URL locale
http://localhost:3000
```

## üîß Configuration avanc√©e

### Timeouts optimis√©s

```javascript
// OpenAI (embeddings)
timeout: 600000,  // 10 minutes

// Claude (g√©n√©ration)
timeout: 900000,  // 15 minutes

// Pinecone (recherche)
timeout: 30000,   // 30 secondes
```

### Limites de transmission

```javascript
const CONFIG = {
  MAX_CHUNK_SIZE: 32768,      // 32KB par chunk SSE
  COMPRESSION_THRESHOLD: 10240, // Compresser si > 10KB
  LARGE_WORKFLOW_THRESHOLD: 50000 // Consid√©r√© comme "gros" si > 50KB
};
```

## üìù Exemples d'utilisation

### G√©n√©rer un workflow simple

```bash
curl -X POST https://vibe-n8n-production.up.railway.app/api/claude \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Workflow simple qui envoie un email de test toutes les heures"
  }'
```

### Am√©liorer un workflow existant

```bash
curl -X POST https://vibe-n8n-production.up.railway.app/api/claude \
  -H "Authorization: Bearer YOUR_API_KEY" \
  -H "Content-Type: application/json" \
  -d '{
    "prompt": "Ajoute une notification Slack en cas d'erreur",
    "baseWorkflow": {
      "name": "Mon workflow",
      "nodes": [...],
      "connections": {...}
    }
  }'
```

### √âcouter le streaming SSE

```javascript
const eventSource = new EventSource(
  'https://vibe-n8n-production.up.railway.app/api/claude',
  {
    headers: {
      'Authorization': 'Bearer YOUR_API_KEY'
    }
  }
);

eventSource.onmessage = function(event) {
  const data = JSON.parse(event.data);
  console.log('√âtape:', data.type, data.data.message);
  
  if (data.type === 'complete') {
    console.log('Workflow g√©n√©r√©:', data.data.workflow);
  }
};
```

## üîç D√©pannage

### Probl√®mes courants

#### "Missing required environment variables"
- **Cause** : Variables d'environnement manquantes
- **Solution** : V√©rifiez `.env` et Railway/Vercel settings

#### "Pinecone index not found"
- **Cause** : Index Pinecone mal configur√©
- **Solution** : V√©rifiez `PINECONE_WORKFLOW_INDEX=n8n-workflows`

#### "Claude API rate limit"
- **Cause** : Limite de taux Claude d√©pass√©e
- **Solution** : Attendez ou augmentez les limites

#### "Workflow too large for SSE"
- **Cause** : Workflow > 1MB m√™me apr√®s compression
- **Solution** : Le syst√®me utilise automatiquement le chunking

### Debug logs

```bash
# Activer les logs d√©taill√©s
export DEBUG=1

# V√©rifier les fichiers debug g√©n√©r√©s
ls debug/
# claude-prompt-streaming.json
# claude-raw-response.txt
# system-prompt-streaming.txt
# user-prompt-streaming.txt
```

### Health checks

```bash
# V√©rifier le statut du backend
curl https://vibe-n8n-production.up.railway.app/api/status

# V√©rifier les endpoints
curl https://vibe-n8n-production.up.railway.app/api
```

## üìä Performance

### M√©triques typiques

| M√©trique | Valeur typique |
|----------|----------------|
| Temps de recherche Pinecone | 0.2 - 0.8s |
| Temps de g√©n√©ration Claude | 5 - 30s |
| Workflow simple (< 10KB) | 8 - 15s |
| Workflow moyen (10-100KB) | 12 - 25s |
| Gros workflow (> 100KB) | 20 - 45s |

### Optimisations

- **Cache Pinecone** : R√©sultats mis en cache 5min
- **Streaming Claude** : R√©ponse en temps r√©el
- **Compression gzip** : R√©duction 60-80% de la taille
- **Chunking adaptatif** : Transmission progressive

## üîí S√©curit√©

### Authentification

- **Bearer token** requis pour toutes les requ√™tes
- **CORS** configur√© pour domaines autoris√©s
- **Rate limiting** c√¥t√© Claude et Pinecone

### Validation

- **Input sanitization** des prompts utilisateur
- **JSON validation** des workflows g√©n√©r√©s
- **Size limits** pour √©viter les abus

## üìÑ License

MIT License - Compatible avec l'√©cosyst√®me n8n open source.

---

**D√©velopp√© avec ‚ù§Ô∏è pour la communaut√© n8n**

*Backend RAG intelligent aliment√© par Claude 4 Sonnet, Pinecone et 2055+ workflows r√©els* 